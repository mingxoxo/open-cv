#include <iostream>
#include <stdio.h>

#include <opencv2/core.hpp>
#include <opencv2/core/utility.hpp>
#include <opencv2/core/ocl.hpp>
#include <opencv2/imgcodecs.hpp>
#include <opencv2/highgui.hpp>
#include <opencv2/features2d.hpp>
#include <opencv2/calib3d.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/xfeatures2d.hpp>


using namespace cv;
using namespace std;
using namespace cv::xfeatures2d;

#define DEBUG 1
Mat deleteBlackZone(const Mat &image)
{
	Mat resultGray;
	Mat result;
	image.copyTo(result);

	cvtColor(image, resultGray, CV_RGB2GRAY);

	medianBlur(resultGray, resultGray, 3);
	// 첫번째 매개변수 : 원본 이미지, 두번째 : 필터를 거친 이미지 세번째 : 작은영역의 사이즈
	Mat resultTh;
	vector<vector<Point> > contours;
	vector<Vec4i> hierarchy;

	threshold(resultGray, resultTh, 1, 255, 0);
	findContours(resultTh, contours, hierarchy, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_SIMPLE);
	//영상 내에서 연결 컴포넌트의 외곽선을 추출하는 함수
	//CV_RETR_EXTERNAL : 외부 외곽선 검색
	//CV_CHAIN_APPROX_SIMPLE : 마지막 점이 수평 또는 수직, 대각선 외곽선에 포함됨

	Mat besta = Mat(contours[0]);
	/*int min_areaa = contourArea(contours[0]);
	int buenoa = 0;
	for (int i = 0; i < contours.size(); i++) {
		if (contourArea(contours[i]) < min_areaa)
		{
			min_areaa = contourArea(contours[i]);
			besta = Mat(contours[i]);
			buenoa = i;
			cout << i << endl;
		}
	}*/
	Rect a = boundingRect(besta);
	cv::Mat half(result, a);
	return half; 
	
}

Mat panorama(Mat matLeftImage, Mat  matRightImage) {
	Mat matGrayLImage;
	Mat matGrayRImage;

	imshow("L", matLeftImage);
	imshow("R", matRightImage);
	waitKey(1);

	//Gray 이미지로 변환
	cvtColor(matLeftImage, matGrayLImage, CV_RGB2GRAY);
	cvtColor(matRightImage, matGrayRImage, CV_RGB2GRAY);

	//step 1 SURF이용해서 특징점 결정
	int nMinHessian = 400; // threshold (한계점)???????
	Ptr<SurfFeatureDetector> Detector = SURF::create(nMinHessian);

	vector <KeyPoint> vtKeypointsObject, vtKeypointsScene;

	Detector->detect(matGrayLImage, vtKeypointsObject);
	Detector->detect(matGrayRImage, vtKeypointsScene);

	Mat matLImageKeypoints;
	Mat matRImageKeypoints;
	drawKeypoints(matGrayLImage, vtKeypointsObject, matLImageKeypoints, Scalar::all(-1), DrawMatchesFlags::DEFAULT);
	drawKeypoints(matGrayRImage, vtKeypointsScene, matRImageKeypoints, Scalar::all(-1), DrawMatchesFlags::DEFAULT);

	imshow("LK", matLImageKeypoints);
	imshow("RK", matRImageKeypoints);
	waitKey(1);

	//step 2 기술자
	Ptr<SurfDescriptorExtractor> Extractor = SURF::create();

	Mat matDescriptorsObject, matDescriptorsScene;

	Extractor->compute(matGrayLImage, vtKeypointsObject, matDescriptorsObject);
	Extractor->compute(matGrayRImage, vtKeypointsScene, matDescriptorsScene);
	//descriptor(기술자)들 사이의 매칭 결과를 matches에 저장한다.
	FlannBasedMatcher Matcher; //kd트리를 사용하여 매칭을 빠르게 수행
	vector <DMatch> matches;
	Matcher.match(matDescriptorsObject, matDescriptorsScene, matches);

	Mat matGoodMatches1;
	drawMatches(matGrayLImage, vtKeypointsObject, matGrayRImage, vtKeypointsScene, matches, matGoodMatches1, Scalar::all(-1), Scalar::all(-1), vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
	imshow("allmatches", matGoodMatches1);
	waitKey(1);
	double dMaxDist = matches[0].distance;
	double dMinDist = matches[0].distance;
	double dDistance;

	// 두 개의 keypoint 사이에서 min-max를 계산한다
	for (int i = 0; i < matDescriptorsObject.rows; i++) {
		dDistance = matches[i].distance;

		if (dDistance < dMinDist) dMinDist = dDistance;
		if (dDistance < dMaxDist) dMaxDist = dDistance;
	}
	printf("max_dist : %f \n", dMaxDist);
	printf("max_dist : %f \n", dMinDist);
	// 값이 작을수록 matching이 잘 된 것
	//min의 값의 3.5배까지만 goodmatch로 인정해주겠다

	vector<DMatch>good_matches;

	for (int i = 0; i < matDescriptorsObject.rows; i++) {
		if (matches[i].distance < 3.5 * dMinDist)
			good_matches.push_back(matches[i]);
	}

	//keypoint들과 matching 결과 ("good" matched point)를 선으로 연결하여 이미지에 그려 표시
	Mat matGoodMatches;
	drawMatches(matGrayLImage, vtKeypointsObject, matGrayRImage, vtKeypointsScene, good_matches, matGoodMatches, Scalar::all(-1), Scalar::all(-1), vector<char>(), DrawMatchesFlags::NOT_DRAW_SINGLE_POINTS);
	imshow("good-matches", matGoodMatches);
	waitKey(3000);
	//Point2f형으로 변환
	vector <Point2f> obj;
	vector <Point2f> scene;

	for (int i = 0; i < good_matches.size();i++) {
		obj.push_back(vtKeypointsObject[good_matches[i].queryIdx].pt);
		scene.push_back(vtKeypointsScene[good_matches[i].trainIdx].pt);
	}
	Mat HomoMatrix = findHomography(scene, obj, CV_RANSAC);
	//RANSAC기법을 이용하여 첫 번째 매개변수와 두번째 매개변수 사이의 3*3 크기의 투영행렬변환 H를 구한다
	cout << HomoMatrix << endl;

	//Homograpy matrix를 사용하여 이미지를 삐뚤게
	Mat matResult;

	warpPerspective(matRightImage, matResult, HomoMatrix, Size(matRightImage.cols * 2, matRightImage.rows * 1.5), INTER_CUBIC);

	Mat matPanorama;
	matPanorama = matResult.clone();
	//matResult = imagecut(matGrayLImage, matResult,  HomoMatrix);
	imshow("wrap", matResult);
	waitKey(3000);
	//warpPerspective(image2, result, T*H, cv::Size(image1.cols + image2.cols * 2, image1.rows + image2.rows * 2));
	//cv::Mat half(result, cv::Rect(image2.cols, image2.rows, image1.cols, image1.rows));
	//image1.copyTo(half);
	
	Mat matROI(matPanorama, Rect(0, 0, matLeftImage.cols, matLeftImage.rows));
	matLeftImage.copyTo(matROI);
	matPanorama = deleteBlackZone(matPanorama);
	imshow("Panorama", matPanorama);
	waitKey(3000);
	return matPanorama;
}

int main()
{
	Mat img1;
	Mat img2;
	Mat img3;
	Mat panoram;

	img1 = imread("C:/opencv-2-4-13-6/S1.jpg", IMREAD_COLOR);
	img2 = imread("C:/opencv-2-4-13-6/S2.jpg", IMREAD_COLOR);
	img3 = imread("C:/opencv-2-4-13-6/S3.jpg", IMREAD_COLOR);

	if (img1.empty() || img2.empty() || img3.empty()) return -1;

	panoram = panorama(img1, img2);
	panoram = panorama(panoram, img3);
	imshow("최종 파노라마", panoram);
	waitKey();
	return 0;
}
